from transformers import pipeline
import os
import json


def merge_entities(entities, location):
	merged = []
	current_entity = None

	for entity in entities:
		label = entity["entity"].split("-")[-1]  # Remove B- or I-
		word = entity["word"].replace("##", "")

		if entity["entity"].startswith("B-") or current_entity is None:
			if current_entity:
				merged.append(current_entity)
			current_entity = {
				"start_idx": entity["start"],
				"end_idx": entity["end"] - 1,
				"location": location,
				"text_span": word,
				"label": label,
			}
		else:
			if entity["start"] == current_entity["end_idx"] + 1:
				current_entity["text_span"] += word
			else:
				current_entity["text_span"] += " " + word
			current_entity["end_idx"] = (
				entity["end"] - 1
			)  # end_idx generated by classifier is off by 1 compared to indexes in training data

	if current_entity:
		merged.append(current_entity)

	return merged


def ner_inference(test_data, classifier):
	result = {}

	for paper_id, content in test_data.items():
		entities_found = []

		title_inference = classifier(content["metadata"]["title"])
		entities_found.extend(merge_entities(title_inference, "title"))

		abstract_inference = classifier(content["metadata"]["abstract"])
		entities_found.extend(merge_entities(abstract_inference, "abstract"))

		result[paper_id] = {"entities": entities_found}

	return result


if __name__ == "__main__":
	file_path = os.path.join("data", "Annotations", "Dev", "json_format", "dev.json")
	classifier = pipeline("ner", model="And3rsen/GutBrainIE_NER_v0")

	with open(file_path, "r", encoding="utf-8") as f:
		test_data = json.load(f)

	result = ner_inference(test_data, classifier)

	with open("inference_results.json", "w") as f:
		json.dump(result, f, indent=4)
